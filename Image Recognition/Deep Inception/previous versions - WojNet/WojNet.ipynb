{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.31687\u001b[0m\u001b[0m | time: 35.476s\n",
      "\u001b[2K\r",
      "| Adam | epoch: 001 | loss: 0.31687 - acc: 0.9283 -- iter: 42000/42000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.fit({'input': X}, {'target': Y}, n_epoch = 1,\\n           validation_set=({'input': testX}, {'target': testY}), show_metric=True, run_id='convnet')\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_utils import to_categorical\n",
    "from import_data import *\n",
    "\n",
    "# Acquiring the data\n",
    "datasets_source = '/media/arcyfelix/DEA8A421A8A3F665/1 GitHub/Python3/Python3/Machine-Learning/Kaggle Competitions/datasets'\n",
    "#datasets_source = '/media/arcyfelix/1E6848486848213F/1 GitHub/Python3/Python3/Machine-Learning/Kaggle Competitions/datasets'\n",
    "\n",
    "folder = 'Digit Recognizer'\n",
    "file_name = 'train.csv'\n",
    "specific_dataset_source = datasets_source + '/' + folder + '/' + file_name\n",
    "output_columns = ['label']\n",
    "\n",
    "data = import_csv(specific_dataset_source, shuffle = True)\n",
    "x_data, y_data = get_xy_mutual(data, output_columns, type = 'numpy')\n",
    "\n",
    "x_data = standalization_divide(x_data, 255)\n",
    "get_info(x_data, 'input')\n",
    "\n",
    "num_samples = x_data.shape[0]\n",
    "input_features = x_data.shape[1]\n",
    "\n",
    "number_of_labels = labels_info(y_data)\n",
    "y_data_as_numbers = labels_as_numbers(y_data)\n",
    "\n",
    "split_percentage = 80\n",
    "x_train, x_val = cross_validation(x_data, split_percentage)\n",
    "\n",
    "y_train = np.array(y_data_as_numbers[0:(int(x_data.shape[0]/(100/split_percentage)))])\n",
    "y_val = np.array(y_data_as_numbers[(int(x_data.shape[0]/(100/split_percentage))):x_data.shape[0]])\n",
    "\n",
    "# Shaping data to the correct shape.\n",
    "x_data = x_data.reshape([-1, 28, 28, 1])\n",
    "y_data = to_categorical(y_data, nb_classes = 10)\n",
    "\n",
    "print('Size of the intput '+ str(x_data.shape))\n",
    "print('Size of the output '+ str(y_data.shape))\n",
    "print('First five examples of one-hot encoded output:')\n",
    "print(y_data[:5, :])\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Building convolutional network\n",
    "network = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "\n",
    "network = conv_2d(network, 10, 3, activation = 'relu')\n",
    "\n",
    "# Hidden layer 1\n",
    "network = fully_connected(network, 256, activation='relu')\n",
    "network = dropout(network, 0.8)\n",
    "#network = local_response_normalization(network)\n",
    "\n",
    "# Hidden layer 2\n",
    "network = fully_connected(network, 256, activation='relu')\n",
    "network = dropout(network, 0.8)\n",
    "\n",
    "# Hidden layer 3\n",
    "network = fully_connected(network, 256, activation='relu')\n",
    "network = dropout(network, 0.8)\n",
    "\n",
    "# Hidden layer 4\n",
    "network = fully_connected(network, 256, activation='relu')\n",
    "network = dropout(network, 0.8)\n",
    "\n",
    "network = fully_connected(network, 10, activation='softmax')\n",
    "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
    "                     loss='categorical_crossentropy', name='target')\n",
    "\n",
    "# Training\n",
    "# model = tflearn.DNN(network, tensorboard_verbose = 3, tensorboard_dir='./logs')\n",
    "\n",
    "model = tflearn.DNN(network, tensorboard_verbose = 0, tensorboard_dir='./logs') # checkpoint_path = '/loga/model_vgg',\n",
    "model.fit(x_data, y_data, n_epoch = 1, shuffle = True,\n",
    "          show_metric = True, batch_size = 100, #snapshot_step = 100,\n",
    "          snapshot_epoch = False, run_id = 'vgg_digits_adam')\n",
    "\n",
    "\n",
    "'''\n",
    "model.fit({'input': X}, {'target': Y}, n_epoch = 1,\n",
    "           validation_set=({'input': testX}, {'target': testY}), show_metric=True, run_id='convnet')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 10)\n",
      "0.98489767313\n",
      "**********************************************************************\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 10)\n",
      "1.0\n",
      "**********************************************************************\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 10)\n",
      "0.99941265583\n",
      "**********************************************************************\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 10)\n",
      "0.933474183083\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index in range(11,15):\n",
    "    predicted_as_prob = np.array(model.predict(x_data[index].reshape([1,28,28,1])))\n",
    "    print('*' * 70)\n",
    "    print(type(predicted_as_prob))\n",
    "    print(predicted_as_prob.shape)\n",
    "    #print(predicted_as_prob)\n",
    "    #print(predicted_as_prob.max())\n",
    "    print(np.amax(predicted_as_prob))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#predicted_as_idx = np.where(predicted_as_prob == predicted_as_prob.max())[1]\n",
    "#print(predicted_as_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
