{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 83999  | total loss: \u001b[1m\u001b[32m0.09802\u001b[0m\u001b[0m | time: 48.759s\n",
      "| Adam | epoch: 500 | loss: 0.09802 - acc: 0.9731 -- iter: 33400/33600\n",
      "Training Step: 84000  | total loss: \u001b[1m\u001b[32m0.09336\u001b[0m\u001b[0m | time: 50.055s\n",
      "| Adam | epoch: 500 | loss: 0.09336 - acc: 0.9738 | val_loss: 0.13843 - val_acc: 0.9688 -- iter: 33600/33600\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.merge_ops import merge\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_utils import to_categorical\n",
    "\n",
    "from tflearn.helpers.trainer import Trainer\n",
    "from import_data import *\n",
    "\n",
    "# Acquiring the data\n",
    "\n",
    "folder = 'Digit Recognizer'\n",
    "file_name = 'train.csv'\n",
    "specific_dataset_source = folder + '/' + file_name\n",
    "output_columns = ['label']\n",
    "\n",
    "data = import_csv(specific_dataset_source, shuffle = True)\n",
    "x_data, y_data = get_xy_mutual(data, output_columns, type = 'numpy')\n",
    "\n",
    "x_data = standalization_divide(x_data, 255)\n",
    "get_info(x_data, 'input')\n",
    "\n",
    "num_samples = x_data.shape[0]\n",
    "input_features = x_data.shape[1]\n",
    "\n",
    "number_of_labels = labels_info(y_data)\n",
    "y_data_as_numbers = labels_as_numbers(y_data)\n",
    "\n",
    "split_percentage = 80\n",
    "x_train, x_val = cross_validation(x_data, split_percentage)\n",
    "\n",
    "y_train = np.array(y_data_as_numbers[0:(int(x_data.shape[0]/(100/split_percentage)))])\n",
    "y_val = np.array(y_data_as_numbers[(int(x_data.shape[0]/(100/split_percentage))):x_data.shape[0]])\n",
    "\n",
    "# Shaping data to the correct shape.\n",
    "x_train = x_train.reshape([-1, 28, 28, 1])\n",
    "x_val = x_val.reshape([-1, 28, 28, 1])\n",
    "y_train = to_categorical(y_train, nb_classes = 10)\n",
    "y_val = to_categorical(y_val, nb_classes = 10)\n",
    "\n",
    "\n",
    "print('Size of the intput '+ str(x_data.shape))\n",
    "print('Size of the output '+ str(y_data.shape))\n",
    "print('First five examples of one-hot encoded output:')\n",
    "print(y_train[:5, :])\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Building convolutional network\n",
    "network = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "\n",
    "#\n",
    "branch1 = conv_2d(network, 32, [2, 2], activation = 'relu')\n",
    "branch1 = dropout(branch1, 0.5)\n",
    "\n",
    "branch2 = conv_2d(network, 16, [3, 3], activation = 'relu')\n",
    "branch2 = dropout(branch2, 0.5)\n",
    "branch2 = conv_2d(branch2, 32, [2, 2], activation = 'relu')\n",
    "branch2 = dropout(branch2, 0.5)\n",
    "\n",
    "branch3 = conv_2d(network, 8, [5, 5], activation = 'relu')\n",
    "branch3 = dropout(branch3, 0.5)\n",
    "branch3 = conv_2d(branch3, 16, [3, 3], activation = 'relu')\n",
    "branch3 = dropout(branch3, 0.5)\n",
    "branch3 = conv_2d(branch3, 32, [2, 2], activation = 'relu')\n",
    "branch3 = dropout(branch3, 0.5)\n",
    "\n",
    "branch4 = conv_2d(network, 4, [7, 7], activation = 'relu')\n",
    "branch4 = dropout(branch4, 0.5)\n",
    "branch4 = conv_2d(branch4, 8, [5, 5], activation = 'relu')\n",
    "branch4 = dropout(branch4, 0.5)\n",
    "branch4 = conv_2d(branch4, 16, [3, 3], activation = 'relu')\n",
    "branch4 = dropout(branch4, 0.5)\n",
    "branch4 = conv_2d(branch4, 32, [2, 2], activation = 'relu')\n",
    "branch4 = dropout(branch4, 0.5)\n",
    "\n",
    "# Hidden layer 3\n",
    "merged_layers = merge((branch1, branch2, branch3, branch4), mode = 'elemwise_sum', name = 'Merge')\n",
    "\n",
    "# Hidden layer 4\n",
    "merged_layersk = fully_connected(merged_layers, 10, activation='relu')\n",
    "merged_layers = dropout(merged_layers, 0.5)\n",
    "\n",
    "merged_layers = fully_connected(merged_layers, 10, activation = 'softmax')\n",
    "network = regression(merged_layers, optimizer = 'adam', learning_rate = 0.005,\n",
    "                     loss = 'categorical_crossentropy', name ='target')\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Training\n",
    "# model = tflearn.DNN(network, tensorboard_verbose = 3, tensorboard_dir='./logs')\n",
    "\n",
    "model = tflearn.DNN(network, tensorboard_verbose = 3, tensorboard_dir = './logs', best_checkpoint_path = './checkpoints/best/best_val', max_checkpoints = 1)\n",
    "# checkpoint_path ='./checkpoints/checkpoint',\n",
    "\n",
    "model.fit(x_train, y_train, n_epoch = 500, validation_set = (x_val, y_val),\n",
    "          show_metric = True, batch_size = 200, shuffle = True, #snapshot_step = 100,\n",
    "          snapshot_epoch = True, run_id = 'WojNet')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/arcyfelix/Dropbox/ABB THESIS - Wojciech Orzechowski/files/Python/topologies/ConvNet/WojNet/checkpoints/best/best_val9721\n"
     ]
    }
   ],
   "source": [
    "# Loading the best accuracy checkpoint (accuracy over the validation data)\n",
    "model.load('./checkpoints/best/best_val9721')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99860119047619045]\n",
      "[0.97214285736992245]\n",
      "It took 0.474408388 seconds.\n",
      "(2000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor index in range(11,15):\\n    predicted_as_prob = np.array(model.predict(x_data[index].reshape([1,28,28,1])))\\n    print('*' * 70)\\n    print(type(predicted_as_prob))\\n    print(predicted_as_prob.shape)\\n    #print(predicted_as_prob)\\n    #print(predicted_as_prob.max())\\n    print(np.amax(predicted_as_prob))\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the best accuracy checkpoint (accuracy over the validation data)\n",
    "#model.load('./checkpoints/best/model9454')\n",
    "\n",
    "'''\n",
    "print('*' * 70)\n",
    "print('Model is successfully loaded for the best performance!')\n",
    "'''\n",
    "\n",
    "print(model.evaluate(x_train, y_train))\n",
    "print(model.evaluate(x_val, y_val))\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "prediction = model.predict_label(x_data[0:2000].reshape([-1,28,28,1]))\n",
    "\n",
    "print ('It took', '{0:.9f}'.format(time.time()-start), 'seconds.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(prediction.shape)\n",
    "'''\n",
    "model.predict_label(x_data.reshape([1,28,28,1])))\n",
    "\tpredicted_as_prob = np.array(model.predict(x_data[index].reshape([1,28,28,1])))\n",
    "\tprint('*' * 70)\n",
    "\n",
    "\tprint(predicted_as_prob)\n",
    "\tprint(predicted_as_label)\n",
    "\tprint(predicted_as_label[0, -1])\n",
    "\tprint(predicted_as_prob.max())\n",
    "'''\n",
    "\n",
    "'''\n",
    "for index in range(11,15):\n",
    "    predicted_as_prob = np.array(model.predict(x_data[index].reshape([1,28,28,1])))\n",
    "    print('*' * 70)\n",
    "    print(type(predicted_as_prob))\n",
    "    print(predicted_as_prob.shape)\n",
    "    #print(predicted_as_prob)\n",
    "    #print(predicted_as_prob.max())\n",
    "    print(np.amax(predicted_as_prob))\n",
    "\n",
    "'''\n",
    "\n",
    "#tensorboard --logdir=logs/\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
